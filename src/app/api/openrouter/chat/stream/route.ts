import { NextRequest } from 'next/server';
import { prisma } from '../../../../../lib/db';

export const runtime = 'nodejs';

export async function POST(request: NextRequest) {
  try {
    const body = await request.json();
    const { messages, model, temperature, system, clientId, sessionId } = body || {};

    const OPENROUTER_API_URL = process.env.OPENROUTER_API_URL || 'https://openrouter.ai/api/v1/chat/completions';
    const OPENROUTER_API_KEY = process.env.OPENROUTER_API_KEY;
    if (!OPENROUTER_API_KEY) {
      return new Response('OpenRouter API key not configured', { status: 500 });
    }

    const conversationHistory = (messages || []).slice(-5);
    const lastMessage = (messages || [])[messages.length - 1]?.content || '';
    const isFirstQuestion = (messages || []).length <= 2;

    const isGreeting = /^(Ø£Ù‡Ù„Ø§|Ù…Ø±Ø­Ø¨Ø§|Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…|ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±|Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±|ÙƒÙŠÙ Ø§Ù„Ø­Ø§Ù„|Ø¥Ù†Øª Ø¹Ø§Ù…Ù„ Ø¥ÙŠÙ‡|Ø¥Ù†Øª Ø¹Ø§Ù…Ù„ÙŠÙ† Ø¥ÙŠÙ‡)/i.test(lastMessage);
    const isAmbiguous = /^(Ù…Ù…|Ù†Ù†|Ø®Øº|Ø§Ù‡|Ø£Ù‡|Ø§ÙŠÙ‡|Ø¥ÙŠÙ‡|Ù…Ø´ ÙØ§Ù‡Ù…|Ù…Ø´ Ø¹Ø§Ø±Ù)/i.test(lastMessage);
    const isPriceQuestion = /(ÙƒØ§Ù…|Ø¨ÙƒØ§Ù…|Ø§Ù„Ø³Ø¹Ø±|Ø§Ù„ØªÙƒÙ„ÙØ©|Ø§Ù„Ø­Ø¨Ø©|ÙŠØ¹Ù…Ù„ÙˆØ§ ÙƒØ§Ù…|Ø¨ÙŠÙƒÙ„Ù ÙƒØ§Ù…)/i.test(lastMessage);
    const isCasual = /(ØªÙ…Ø§Ù…|Ù…Ø§Ø´ÙŠ|Ø£ÙˆÙƒÙŠ|Ø­Ù„Ùˆ|Ù…Ù…ØªØ§Ø²|ÙƒÙˆÙŠØ³|Ø¹Ø¸ÙŠÙ…)/i.test(lastMessage);

    let computedSystemPrompt = '';
    let maxTokens = 120;
    if (isFirstQuestion) {
      if (isGreeting) {
        computedSystemPrompt = `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ÙˆØ¯ÙˆØ¯ ÙˆÙ…Ø­Ø¨ Ù…Ù† Ø¥ÙŠØ¬ÙŠ Ø£ÙØ±ÙŠÙƒØ§. Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­ÙŠØ© Ø¨Ù„Ø·Ù ÙˆÙˆØ¯ØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ© Ø®ÙÙŠÙØ© ðŸ˜Š. Ø§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ø§Ù‹ ÙˆØ¯ÙˆØ¯Ø§Ù‹ Ù„Ù…ÙˆØ§ØµÙ„Ø© Ø§Ù„Ù†Ù‚Ø§Ø´. Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 80 ØªÙˆÙƒÙ†.`;
        maxTokens = 80;
      } else {
        computedSystemPrompt = `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ÙˆØ¯ÙˆØ¯ ÙˆÙ…Ø­Ø¨ Ù…Ù† Ø¥ÙŠØ¬ÙŠ Ø£ÙØ±ÙŠÙƒØ§. Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø¥ÙŠØ¬Ø§Ø² (2-3 Ø¬Ù…Ù„Ø©) ÙˆØ§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ø§Ù‹ ÙˆØ§Ø­Ø¯Ø§Ù‹ Ù„Ù…ÙˆØ§ØµÙ„Ø© Ø§Ù„Ù†Ù‚Ø§Ø´. Ø§Ø³ØªØ®Ø¯Ù… Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ© Ø®ÙÙŠÙØ© ðŸ˜Š. Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 100 ØªÙˆÙƒÙ†.`;
        maxTokens = 100;
      }
    } else {
      if (isAmbiguous) {
        computedSystemPrompt = `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ÙˆØ¯ÙˆØ¯ ÙˆÙ…Ø­Ø¨. Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙƒØªØ¨ Ù†Øµ ØºÙŠØ± ÙˆØ§Ø¶Ø­ØŒ Ø±Ø¯ Ø¹Ù„ÙŠÙ‡ Ø¨Ù„Ø·Ù ÙˆØ§Ø·Ù„Ø¨ Ø§Ù„ØªÙˆØ¶ÙŠØ­ Ø¨Ø´ÙƒÙ„ ÙˆØ¯ÙˆØ¯ ðŸ˜…. Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 60 ØªÙˆÙƒÙ†.`;
        maxTokens = 60;
      } else if (isPriceQuestion) {
        computedSystemPrompt = `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ÙˆØ¯ÙˆØ¯ ÙˆÙ…Ø­Ø¨. Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙŠØ³Ø£Ù„ Ø¹Ù† Ø§Ù„Ø³Ø¹Ø±ØŒ ÙÙ‡Ù… Ù‚ØµØ¯Ùƒ ðŸ‘ ÙˆØ§Ø´Ø±Ø­ Ø£Ù† Ø§Ù„Ø£Ø³Ø¹Ø§Ø± ØªØ®ØªÙ„Ù Ø­Ø³Ø¨ Ø§Ù„Ø®Ø¯Ù…Ø©. Ø§Ø·Ù„Ø¨ ØªÙØ§ØµÙŠÙ„ Ø£ÙƒØ«Ø±. Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 100 ØªÙˆÙƒÙ†.`;
        maxTokens = 100;
      } else if (isCasual) {
        computedSystemPrompt = `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ÙˆØ¯ÙˆØ¯ ÙˆÙ…Ø­Ø¨. Ø§Ù„Ø¹Ù…ÙŠÙ„ ÙƒØªØ¨ Ø±Ø¯ Ø¹Ø§Ø¯ÙŠØŒ Ø±Ø¯Ù‡ Ø¹Ù„ÙŠÙ‡ Ø¨Ù†ÙØ³ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ÙˆØ¯ÙˆØ¯ ðŸ˜Š. Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 80 ØªÙˆÙƒÙ†.`;
        maxTokens = 80;
      } else {
        computedSystemPrompt = `Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ ÙˆØ¯ÙˆØ¯ ÙˆÙ…Ø­Ø¨ Ù…Ù† Ø¥ÙŠØ¬ÙŠ Ø£ÙØ±ÙŠÙƒØ§. Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø¥ÙŠØ¬Ø§Ø² (3-4 Ø¬Ù…Ù„Ø©) ÙˆØ§Ø·Ø±Ø­ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø¢Ø®Ø± Ù„ØªØ¹Ù…ÙŠÙ‚ Ø§Ù„Ù†Ù‚Ø§Ø´. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø¬Ø§Ù†Ø¨ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·. Ø§Ø³ØªØ®Ø¯Ù… Ø±Ù…ÙˆØ² ØªØ¹Ø¨ÙŠØ±ÙŠØ© Ø®ÙÙŠÙØ© ðŸ˜Š. Ù„Ø§ ØªØªØ¬Ø§ÙˆØ² 120 ØªÙˆÙƒÙ†.`;
        maxTokens = 120;
      }
    }

    if (conversationHistory.length > 1) {
      computedSystemPrompt += `\n\nØªØ°ÙƒØ±: Ø£Ù†Øª ÙÙŠ Ù†Ù‚Ø§Ø´ ØªÙØ§Ø¹Ù„ÙŠ Ù…Ø³ØªÙ…Ø±. Ù„Ø§ ØªØ¨Ø¯Ø£ Ù…Ù† Ø¬Ø¯ÙŠØ¯ØŒ Ø±Ø¨Ø· Ø±Ø¯Ùƒ Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚.`;
    }

    const queryClientId = request.nextUrl.searchParams.get('clientId');
    const clientIdentifier = clientId || queryClientId || null;
    let client: any = null;
    if (clientIdentifier) {
      client = await (prisma as any).client.findFirst({
        where: { OR: [{ id: clientIdentifier }, { email: clientIdentifier }] }
      });
    }

          const fallbackModel = process.env.OPENROUTER_MODEL || 'qwen/qwen2.5-vl-32b-instruct:free';
      const selectedModel = model || fallbackModel;
      const finalTemperature = typeof temperature === 'number' ? temperature : 0.7;
      const finalSystemPrompt = typeof system === 'string' ? system : computedSystemPrompt;

    const requestBody = {
      model: selectedModel,
      messages: [
        { role: 'system', content: finalSystemPrompt },
        ...conversationHistory.map((m: any) => ({ role: m.role, content: m.content }))
      ],
      temperature: finalTemperature,
      top_p: 0.9,
      max_tokens: maxTokens,
      stream: true,
      stop: ['\n\n', '1.', '2.', '3.', '4.', '5.'],
      repetition_penalty: 1.2,
    } as any;

    const callModel = async (modelName: string) => {
      return fetch(OPENROUTER_API_URL, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
          'Content-Type': 'application/json',
          'Accept': 'text/event-stream',
          'HTTP-Referer': process.env.NEXT_PUBLIC_SITE_URL || 'http://localhost:3000',
          'X-Title': 'Egy Africa AI'
        },
        body: JSON.stringify({ ...requestBody, model: modelName })
      });
    };

    let upstream = await callModel(selectedModel);
    if (!upstream.ok) {
      const backup = await callModel(fallbackModel);
      if (backup.ok) upstream = backup;
    }
    if (!upstream.ok || !upstream.body) {
      return new Response(`OpenRouter error: ${upstream.status}`, { status: upstream.status || 500 });
    }

    const [toClient, toParse] = (upstream.body as ReadableStream<Uint8Array>).tee();

    // Parse SSE to accumulate assistant content and persist after end
    (async () => {
      try {
        const reader = toParse.getReader();
        const decoder = new TextDecoder();
        let buffer = '';
        let assistant = '';
        while (true) {
          const { value, done } = await reader.read();
          if (done) break;
          buffer += decoder.decode(value, { stream: true });
          const parts = buffer.split('\n\n');
          buffer = parts.pop() || '';
          for (const part of parts) {
            if (!part.startsWith('data:')) continue;
            const json = part.slice(5).trim();
            if (json === '[DONE]') continue;
            try {
              const evt = JSON.parse(json);
              const delta = evt?.choices?.[0]?.delta?.content || '';
              const messageContent = evt?.choices?.[0]?.message?.content || '';
              assistant += delta || messageContent || '';
            } catch {}
          }
        }

        const session = sessionId || request.nextUrl.searchParams.get('sessionId') || (globalThis.crypto?.randomUUID?.() || `${Date.now()}-${Math.random()}`);
        let conversation = await (prisma as any).conversation.findFirst({ where: { sessionId: session, clientId: client?.id ?? null } });
        if (!conversation) {
          conversation = await (prisma as any).conversation.create({ data: { sessionId: session, clientId: client?.id ?? null } });
        }
        if (lastMessage) {
          await (prisma as any).message.create({ data: { conversationId: conversation.id, role: 'user', content: lastMessage } });
        }
        if (assistant) {
          await (prisma as any).message.create({ data: { conversationId: conversation.id, role: 'assistant', content: assistant } });
        }
      } catch (e) {
        console.warn('stream persist error:', e);
      }
    })();

    return new Response(toClient, {
      headers: {
        'Content-Type': 'text/event-stream; charset=utf-8',
        'Cache-Control': 'no-cache, no-transform',
        'Connection': 'keep-alive',
        'Transfer-Encoding': 'chunked',
        'X-Accel-Buffering': 'no'
      }
    });
  } catch (e: any) {
    return new Response('Internal server error', { status: 500 });
  }
}


